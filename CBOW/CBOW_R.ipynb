{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "D8OkefRFBD-Y"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding,Dense ,Lambda\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " a. Data preparation"
      ],
      "metadata": {
        "id": "78VnlB4xL1vm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = 'Deep learning is a subset of machine learning that focuses on utilizing neural networks to perform tasks such as classification, regression, and representation learning. The field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data. The adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network. Methods used can be either supervised, semi-supervised or unsupervised. Some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields. These architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board gamef programs, where they have produced results comparable to and in some cases surpassing human expert performance. Early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain. However, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose.'\n"
      ],
      "metadata": {
        "id": "nacDcyRAC1ih"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preprocessing text"
      ],
      "metadata": {
        "id": "j_ja0wxNDOoZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sentences=text.split('.')\n",
        "sentences=[s.lower() for s in sentences]\n",
        "sentences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lx-5javC_OH",
        "outputId": "cc8257eb-3d44-4a8b-cdd7-97596500fbc5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['deep learning is a subset of machine learning that focuses on utilizing neural networks to perform tasks such as classification, regression, and representation learning',\n",
              " ' the field takes inspiration from biological neuroscience and is centered around stacking artificial neurons into layers and \"training\" them to process data',\n",
              " ' the adjective \"deep\" refers to the use of multiple layers (ranging from three to several hundred or thousands) in the network',\n",
              " ' methods used can be either supervised, semi-supervised or unsupervised',\n",
              " ' some common deep learning network architectures include fully connected networks, deep belief networks, recurrent neural networks, convolutional neural networks, generative adversarial networks, transformers, and neural radiance fields',\n",
              " ' these architectures have been applied to fields including computer vision, speech recognition, natural language processing, machine translation, bioinformatics, drug design, medical image analysis, climate science, material inspection and board gamef programs, where they have produced results comparable to and in some cases surpassing human expert performance',\n",
              " ' early forms of neural networks were inspired by information processing and distributed communication nodes in biological systems, particularly the human brain',\n",
              " ' however, current neural networks do not intend to model the brain function of organisms, and are generally seen as low-quality models for that purpose',\n",
              " '']"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenizing the sentences\n",
        "tokenizer=Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "sequences=tokenizer.texts_to_sequences(sentences)\n",
        "print(sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhxMAtyuDWKQ",
        "outputId": "975822ec-899e-4367-b4a1-855d30ca1bdd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6, 7, 10, 27, 28, 8, 11, 7, 12, 29, 30, 31, 4, 1, 3, 32, 33, 34, 13, 35, 36, 2, 37, 7], [5, 38, 39, 40, 14, 15, 41, 2, 10, 42, 43, 44, 45, 46, 47, 16, 2, 48, 49, 3, 50, 51], [5, 52, 6, 53, 3, 5, 54, 8, 55, 16, 56, 14, 57, 3, 58, 59, 17, 60, 9, 5, 18], [61, 62, 63, 64, 65, 19, 66, 19, 17, 67], [20, 68, 6, 7, 18, 21, 69, 70, 71, 1, 6, 72, 1, 73, 4, 1, 74, 4, 1, 75, 76, 1, 77, 2, 4, 78, 22], [79, 21, 23, 80, 81, 3, 22, 82, 83, 84, 85, 86, 87, 88, 24, 11, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 2, 100, 101, 102, 103, 104, 23, 105, 106, 107, 3, 2, 9, 20, 108, 109, 25, 110, 111], [112, 113, 8, 4, 1, 114, 115, 116, 117, 24, 2, 118, 119, 120, 9, 15, 121, 122, 5, 25, 26], [123, 124, 4, 1, 125, 126, 127, 3, 128, 5, 26, 129, 8, 130, 2, 131, 132, 133, 13, 134, 135, 136, 137, 12, 138], []]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index_to_word=tokenizer.index_word\n",
        "word_to_index=tokenizer.word_index\n",
        "print(index_to_word,\"\\n\")\n",
        "print(word_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rBjbQivTDssO",
        "outputId": "e007f813-d941-4d43-c079-3226a1c9c2b6"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{1: 'networks', 2: 'and', 3: 'to', 4: 'neural', 5: 'the', 6: 'deep', 7: 'learning', 8: 'of', 9: 'in', 10: 'is', 11: 'machine', 12: 'that', 13: 'as', 14: 'from', 15: 'biological', 16: 'layers', 17: 'or', 18: 'network', 19: 'supervised', 20: 'some', 21: 'architectures', 22: 'fields', 23: 'have', 24: 'processing', 25: 'human', 26: 'brain', 27: 'a', 28: 'subset', 29: 'focuses', 30: 'on', 31: 'utilizing', 32: 'perform', 33: 'tasks', 34: 'such', 35: 'classification', 36: 'regression', 37: 'representation', 38: 'field', 39: 'takes', 40: 'inspiration', 41: 'neuroscience', 42: 'centered', 43: 'around', 44: 'stacking', 45: 'artificial', 46: 'neurons', 47: 'into', 48: 'training', 49: 'them', 50: 'process', 51: 'data', 52: 'adjective', 53: 'refers', 54: 'use', 55: 'multiple', 56: 'ranging', 57: 'three', 58: 'several', 59: 'hundred', 60: 'thousands', 61: 'methods', 62: 'used', 63: 'can', 64: 'be', 65: 'either', 66: 'semi', 67: 'unsupervised', 68: 'common', 69: 'include', 70: 'fully', 71: 'connected', 72: 'belief', 73: 'recurrent', 74: 'convolutional', 75: 'generative', 76: 'adversarial', 77: 'transformers', 78: 'radiance', 79: 'these', 80: 'been', 81: 'applied', 82: 'including', 83: 'computer', 84: 'vision', 85: 'speech', 86: 'recognition', 87: 'natural', 88: 'language', 89: 'translation', 90: 'bioinformatics', 91: 'drug', 92: 'design', 93: 'medical', 94: 'image', 95: 'analysis', 96: 'climate', 97: 'science', 98: 'material', 99: 'inspection', 100: 'board', 101: 'gamef', 102: 'programs', 103: 'where', 104: 'they', 105: 'produced', 106: 'results', 107: 'comparable', 108: 'cases', 109: 'surpassing', 110: 'expert', 111: 'performance', 112: 'early', 113: 'forms', 114: 'were', 115: 'inspired', 116: 'by', 117: 'information', 118: 'distributed', 119: 'communication', 120: 'nodes', 121: 'systems', 122: 'particularly', 123: 'however', 124: 'current', 125: 'do', 126: 'not', 127: 'intend', 128: 'model', 129: 'function', 130: 'organisms', 131: 'are', 132: 'generally', 133: 'seen', 134: 'low', 135: 'quality', 136: 'models', 137: 'for', 138: 'purpose'} \n",
            "\n",
            "{'networks': 1, 'and': 2, 'to': 3, 'neural': 4, 'the': 5, 'deep': 6, 'learning': 7, 'of': 8, 'in': 9, 'is': 10, 'machine': 11, 'that': 12, 'as': 13, 'from': 14, 'biological': 15, 'layers': 16, 'or': 17, 'network': 18, 'supervised': 19, 'some': 20, 'architectures': 21, 'fields': 22, 'have': 23, 'processing': 24, 'human': 25, 'brain': 26, 'a': 27, 'subset': 28, 'focuses': 29, 'on': 30, 'utilizing': 31, 'perform': 32, 'tasks': 33, 'such': 34, 'classification': 35, 'regression': 36, 'representation': 37, 'field': 38, 'takes': 39, 'inspiration': 40, 'neuroscience': 41, 'centered': 42, 'around': 43, 'stacking': 44, 'artificial': 45, 'neurons': 46, 'into': 47, 'training': 48, 'them': 49, 'process': 50, 'data': 51, 'adjective': 52, 'refers': 53, 'use': 54, 'multiple': 55, 'ranging': 56, 'three': 57, 'several': 58, 'hundred': 59, 'thousands': 60, 'methods': 61, 'used': 62, 'can': 63, 'be': 64, 'either': 65, 'semi': 66, 'unsupervised': 67, 'common': 68, 'include': 69, 'fully': 70, 'connected': 71, 'belief': 72, 'recurrent': 73, 'convolutional': 74, 'generative': 75, 'adversarial': 76, 'transformers': 77, 'radiance': 78, 'these': 79, 'been': 80, 'applied': 81, 'including': 82, 'computer': 83, 'vision': 84, 'speech': 85, 'recognition': 86, 'natural': 87, 'language': 88, 'translation': 89, 'bioinformatics': 90, 'drug': 91, 'design': 92, 'medical': 93, 'image': 94, 'analysis': 95, 'climate': 96, 'science': 97, 'material': 98, 'inspection': 99, 'board': 100, 'gamef': 101, 'programs': 102, 'where': 103, 'they': 104, 'produced': 105, 'results': 106, 'comparable': 107, 'cases': 108, 'surpassing': 109, 'expert': 110, 'performance': 111, 'early': 112, 'forms': 113, 'were': 114, 'inspired': 115, 'by': 116, 'information': 117, 'distributed': 118, 'communication': 119, 'nodes': 120, 'systems': 121, 'particularly': 122, 'however': 123, 'current': 124, 'do': 125, 'not': 126, 'intend': 127, 'model': 128, 'function': 129, 'organisms': 130, 'are': 131, 'generally': 132, 'seen': 133, 'low': 134, 'quality': 135, 'models': 136, 'for': 137, 'purpose': 138}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "b. Generate training data ||\n",
        "Creating contexts and targets"
      ],
      "metadata": {
        "id": "5X9mVL1MEZEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size=len(tokenizer.word_index)+1\n",
        "emb_size=100\n",
        "context_size=2\n",
        "contexts=[]\n",
        "targets=[]\n",
        "for sequence in sequences:\n",
        "  for i in range(context_size,len(sequence)-context_size):\n",
        "    context=[sequence[i-2],sequence[i-1],sequence[i+1],sequence[i+2]]\n",
        "    target=sequence[i]\n",
        "    contexts.append(context)\n",
        "    targets.append(target)\n",
        "\n",
        "print(contexts,\"\\n\")\n",
        "print(targets)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhtuNz8cEOwA",
        "outputId": "42b9a75f-8d8d-4c98-8aab-1a981c7f54fa"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[6, 7, 27, 28], [7, 10, 28, 8], [10, 27, 8, 11], [27, 28, 11, 7], [28, 8, 7, 12], [8, 11, 12, 29], [11, 7, 29, 30], [7, 12, 30, 31], [12, 29, 31, 4], [29, 30, 4, 1], [30, 31, 1, 3], [31, 4, 3, 32], [4, 1, 32, 33], [1, 3, 33, 34], [3, 32, 34, 13], [32, 33, 13, 35], [33, 34, 35, 36], [34, 13, 36, 2], [13, 35, 2, 37], [35, 36, 37, 7], [5, 38, 40, 14], [38, 39, 14, 15], [39, 40, 15, 41], [40, 14, 41, 2], [14, 15, 2, 10], [15, 41, 10, 42], [41, 2, 42, 43], [2, 10, 43, 44], [10, 42, 44, 45], [42, 43, 45, 46], [43, 44, 46, 47], [44, 45, 47, 16], [45, 46, 16, 2], [46, 47, 2, 48], [47, 16, 48, 49], [16, 2, 49, 3], [2, 48, 3, 50], [48, 49, 50, 51], [5, 52, 53, 3], [52, 6, 3, 5], [6, 53, 5, 54], [53, 3, 54, 8], [3, 5, 8, 55], [5, 54, 55, 16], [54, 8, 16, 56], [8, 55, 56, 14], [55, 16, 14, 57], [16, 56, 57, 3], [56, 14, 3, 58], [14, 57, 58, 59], [57, 3, 59, 17], [3, 58, 17, 60], [58, 59, 60, 9], [59, 17, 9, 5], [17, 60, 5, 18], [61, 62, 64, 65], [62, 63, 65, 19], [63, 64, 19, 66], [64, 65, 66, 19], [65, 19, 19, 17], [19, 66, 17, 67], [20, 68, 7, 18], [68, 6, 18, 21], [6, 7, 21, 69], [7, 18, 69, 70], [18, 21, 70, 71], [21, 69, 71, 1], [69, 70, 1, 6], [70, 71, 6, 72], [71, 1, 72, 1], [1, 6, 1, 73], [6, 72, 73, 4], [72, 1, 4, 1], [1, 73, 1, 74], [73, 4, 74, 4], [4, 1, 4, 1], [1, 74, 1, 75], [74, 4, 75, 76], [4, 1, 76, 1], [1, 75, 1, 77], [75, 76, 77, 2], [76, 1, 2, 4], [1, 77, 4, 78], [77, 2, 78, 22], [79, 21, 80, 81], [21, 23, 81, 3], [23, 80, 3, 22], [80, 81, 22, 82], [81, 3, 82, 83], [3, 22, 83, 84], [22, 82, 84, 85], [82, 83, 85, 86], [83, 84, 86, 87], [84, 85, 87, 88], [85, 86, 88, 24], [86, 87, 24, 11], [87, 88, 11, 89], [88, 24, 89, 90], [24, 11, 90, 91], [11, 89, 91, 92], [89, 90, 92, 93], [90, 91, 93, 94], [91, 92, 94, 95], [92, 93, 95, 96], [93, 94, 96, 97], [94, 95, 97, 98], [95, 96, 98, 99], [96, 97, 99, 2], [97, 98, 2, 100], [98, 99, 100, 101], [99, 2, 101, 102], [2, 100, 102, 103], [100, 101, 103, 104], [101, 102, 104, 23], [102, 103, 23, 105], [103, 104, 105, 106], [104, 23, 106, 107], [23, 105, 107, 3], [105, 106, 3, 2], [106, 107, 2, 9], [107, 3, 9, 20], [3, 2, 20, 108], [2, 9, 108, 109], [9, 20, 109, 25], [20, 108, 25, 110], [108, 109, 110, 111], [112, 113, 4, 1], [113, 8, 1, 114], [8, 4, 114, 115], [4, 1, 115, 116], [1, 114, 116, 117], [114, 115, 117, 24], [115, 116, 24, 2], [116, 117, 2, 118], [117, 24, 118, 119], [24, 2, 119, 120], [2, 118, 120, 9], [118, 119, 9, 15], [119, 120, 15, 121], [120, 9, 121, 122], [9, 15, 122, 5], [15, 121, 5, 25], [121, 122, 25, 26], [123, 124, 1, 125], [124, 4, 125, 126], [4, 1, 126, 127], [1, 125, 127, 3], [125, 126, 3, 128], [126, 127, 128, 5], [127, 3, 5, 26], [3, 128, 26, 129], [128, 5, 129, 8], [5, 26, 8, 130], [26, 129, 130, 2], [129, 8, 2, 131], [8, 130, 131, 132], [130, 2, 132, 133], [2, 131, 133, 13], [131, 132, 13, 134], [132, 133, 134, 135], [133, 13, 135, 136], [13, 134, 136, 137], [134, 135, 137, 12], [135, 136, 12, 138]] \n",
            "\n",
            "[10, 27, 28, 8, 11, 7, 12, 29, 30, 31, 4, 1, 3, 32, 33, 34, 13, 35, 36, 2, 39, 40, 14, 15, 41, 2, 10, 42, 43, 44, 45, 46, 47, 16, 2, 48, 49, 3, 6, 53, 3, 5, 54, 8, 55, 16, 56, 14, 57, 3, 58, 59, 17, 60, 9, 63, 64, 65, 19, 66, 19, 6, 7, 18, 21, 69, 70, 71, 1, 6, 72, 1, 73, 4, 1, 74, 4, 1, 75, 76, 1, 77, 2, 4, 23, 80, 81, 3, 22, 82, 83, 84, 85, 86, 87, 88, 24, 11, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 2, 100, 101, 102, 103, 104, 23, 105, 106, 107, 3, 2, 9, 20, 108, 109, 25, 8, 4, 1, 114, 115, 116, 117, 24, 2, 118, 119, 120, 9, 15, 121, 122, 5, 4, 1, 125, 126, 127, 3, 128, 5, 26, 129, 8, 130, 2, 131, 132, 133, 13, 134, 135, 136, 137]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Printing features with target\n",
        "for i in range(5):\n",
        "  words=[]\n",
        "  target=index_to_word.get(targets[i])\n",
        "  for j in contexts[i]:\n",
        "    words.append(index_to_word.get(j))\n",
        "  print(words,\"=>\",target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTh5gmNKGHSy",
        "outputId": "ba8df7ba-3125-49a9-f326-8326dd454030"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['deep', 'learning', 'a', 'subset'] => is\n",
            "['learning', 'is', 'subset', 'of'] => a\n",
            "['is', 'a', 'of', 'machine'] => subset\n",
            "['a', 'subset', 'machine', 'learning'] => of\n",
            "['subset', 'of', 'learning', 'that'] => machine\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating training and testing data\n"
      ],
      "metadata": {
        "id": "Lkyi--EgHLi9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x=np.array(contexts)\n",
        "y=np.array(targets)\n",
        "print(\"Shape of x:\", x.shape)\n",
        "print(\"Shape of y:\", y.shape)\n",
        "# y = y.reshape(-1, 1)\n",
        "# print(\"Shape of x:\", x.shape)\n",
        "# print(\"Shape of y:\", y.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XTvEgGcjGiC_",
        "outputId": "e9c53578-3a68-41ba-9f16-d262e20df1f8"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of x: (164, 4)\n",
            "Shape of y: (164,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=42)"
      ],
      "metadata": {
        "id": "Sq1_xR9aHXpb"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "c. Train model  || *Defining model*"
      ],
      "metadata": {
        "id": "WSX0c1ydHrsw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential([\n",
        "    Embedding(input_dim=vocab_size,output_dim=emb_size,input_length=context_size*2),\n",
        "    Lambda(lambda x:tf.reduce_mean(x,axis=1)),\n",
        "    Dense(256,activation='relu'),\n",
        "    Dense(512,activation='relu'),\n",
        "    Dense(vocab_size,activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cfq2tA6WHgIk",
        "outputId": "942b1d0c-9b69-462d-ce41-41de17ac4111"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',loss='sparse_categorical_crossentropy',metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "mnuakkYbIaz4"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history=model.fit(x_train,y_train,epochs=100,validation_data=(x_test,y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aS7-f8tLIiJr",
        "outputId": "d26aae69-c029-4012-98d3-46f0b6955a3f"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.0232 - loss: 4.9338 - val_accuracy: 0.0000e+00 - val_loss: 4.9385\n",
            "Epoch 2/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.1413 - loss: 4.9099 - val_accuracy: 0.0000e+00 - val_loss: 4.9455\n",
            "Epoch 3/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1124 - loss: 4.8812 - val_accuracy: 0.0000e+00 - val_loss: 4.9603\n",
            "Epoch 4/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0920 - loss: 4.8314 - val_accuracy: 0.0000e+00 - val_loss: 4.9926\n",
            "Epoch 5/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0675 - loss: 4.7495 - val_accuracy: 0.0000e+00 - val_loss: 5.0657\n",
            "Epoch 6/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0794 - loss: 4.5901 - val_accuracy: 0.0000e+00 - val_loss: 5.2342\n",
            "Epoch 7/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0525 - loss: 4.3933 - val_accuracy: 0.0000e+00 - val_loss: 5.6255\n",
            "Epoch 8/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.0594 - loss: 4.1988 - val_accuracy: 0.0000e+00 - val_loss: 6.1925\n",
            "Epoch 9/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0641 - loss: 4.1535 - val_accuracy: 0.0000e+00 - val_loss: 6.4830\n",
            "Epoch 10/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.1252 - loss: 4.0168 - val_accuracy: 0.0303 - val_loss: 6.6082\n",
            "Epoch 11/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1774 - loss: 3.8427 - val_accuracy: 0.0303 - val_loss: 6.7237\n",
            "Epoch 12/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.1753 - loss: 3.7791 - val_accuracy: 0.0303 - val_loss: 6.8654\n",
            "Epoch 13/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.1952 - loss: 3.5857 - val_accuracy: 0.0303 - val_loss: 7.0838\n",
            "Epoch 14/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.2041 - loss: 3.4981 - val_accuracy: 0.0303 - val_loss: 7.1731\n",
            "Epoch 15/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.2498 - loss: 3.3699 - val_accuracy: 0.0303 - val_loss: 7.3445\n",
            "Epoch 16/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.2539 - loss: 3.2479 - val_accuracy: 0.0303 - val_loss: 7.5938\n",
            "Epoch 17/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3171 - loss: 3.0583 - val_accuracy: 0.0303 - val_loss: 7.8065\n",
            "Epoch 18/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.3069 - loss: 2.9737 - val_accuracy: 0.0303 - val_loss: 8.0921\n",
            "Epoch 19/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3530 - loss: 2.7756 - val_accuracy: 0.0303 - val_loss: 8.4621\n",
            "Epoch 20/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4022 - loss: 2.5571 - val_accuracy: 0.0303 - val_loss: 8.9916\n",
            "Epoch 21/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3759 - loss: 2.3711 - val_accuracy: 0.0303 - val_loss: 9.5512\n",
            "Epoch 22/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.4408 - loss: 2.1171 - val_accuracy: 0.0303 - val_loss: 10.0618\n",
            "Epoch 23/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.6109 - loss: 1.8090 - val_accuracy: 0.0303 - val_loss: 10.7058\n",
            "Epoch 24/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.5861 - loss: 1.6759 - val_accuracy: 0.0303 - val_loss: 11.2754\n",
            "Epoch 25/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6860 - loss: 1.4106 - val_accuracy: 0.0000e+00 - val_loss: 11.8286\n",
            "Epoch 26/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7850 - loss: 1.2640 - val_accuracy: 0.0000e+00 - val_loss: 12.5823\n",
            "Epoch 27/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7659 - loss: 1.1592 - val_accuracy: 0.0303 - val_loss: 13.4280\n",
            "Epoch 28/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8452 - loss: 0.9199 - val_accuracy: 0.0303 - val_loss: 14.2010\n",
            "Epoch 29/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8098 - loss: 0.8665 - val_accuracy: 0.0303 - val_loss: 14.9251\n",
            "Epoch 30/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8312 - loss: 0.7217 - val_accuracy: 0.0303 - val_loss: 15.6437\n",
            "Epoch 31/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8854 - loss: 0.6736 - val_accuracy: 0.0000e+00 - val_loss: 16.0973\n",
            "Epoch 32/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8947 - loss: 0.5673 - val_accuracy: 0.0000e+00 - val_loss: 16.4561\n",
            "Epoch 33/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8560 - loss: 0.5489 - val_accuracy: 0.0000e+00 - val_loss: 16.8724\n",
            "Epoch 34/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9604 - loss: 0.4201 - val_accuracy: 0.0000e+00 - val_loss: 17.4120\n",
            "Epoch 35/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9768 - loss: 0.3602 - val_accuracy: 0.0000e+00 - val_loss: 17.8874\n",
            "Epoch 36/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9557 - loss: 0.3510 - val_accuracy: 0.0000e+00 - val_loss: 18.2961\n",
            "Epoch 37/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9634 - loss: 0.3005 - val_accuracy: 0.0000e+00 - val_loss: 18.6189\n",
            "Epoch 38/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9676 - loss: 0.2628 - val_accuracy: 0.0303 - val_loss: 18.8433\n",
            "Epoch 39/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9888 - loss: 0.2175 - val_accuracy: 0.0303 - val_loss: 19.1681\n",
            "Epoch 40/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9650 - loss: 0.2141 - val_accuracy: 0.0000e+00 - val_loss: 19.5479\n",
            "Epoch 41/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9676 - loss: 0.1946 - val_accuracy: 0.0000e+00 - val_loss: 19.9066\n",
            "Epoch 42/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9690 - loss: 0.1601 - val_accuracy: 0.0000e+00 - val_loss: 20.2332\n",
            "Epoch 43/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9867 - loss: 0.1326 - val_accuracy: 0.0000e+00 - val_loss: 20.4812\n",
            "Epoch 44/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9880 - loss: 0.1339 - val_accuracy: 0.0000e+00 - val_loss: 20.7161\n",
            "Epoch 45/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.1208 - val_accuracy: 0.0000e+00 - val_loss: 20.9491\n",
            "Epoch 46/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0924 - val_accuracy: 0.0000e+00 - val_loss: 21.2082\n",
            "Epoch 47/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0918 - val_accuracy: 0.0000e+00 - val_loss: 21.4769\n",
            "Epoch 48/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0826 - val_accuracy: 0.0303 - val_loss: 21.7273\n",
            "Epoch 49/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9944 - loss: 0.0800 - val_accuracy: 0.0303 - val_loss: 21.9668\n",
            "Epoch 50/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0727 - val_accuracy: 0.0303 - val_loss: 22.1714\n",
            "Epoch 51/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0635 - val_accuracy: 0.0303 - val_loss: 22.3928\n",
            "Epoch 52/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 1.0000 - loss: 0.0571 - val_accuracy: 0.0303 - val_loss: 22.6273\n",
            "Epoch 53/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0552 - val_accuracy: 0.0000e+00 - val_loss: 22.8439\n",
            "Epoch 54/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0458 - val_accuracy: 0.0000e+00 - val_loss: 23.0279\n",
            "Epoch 55/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0448 - val_accuracy: 0.0000e+00 - val_loss: 23.1734\n",
            "Epoch 56/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0459 - val_accuracy: 0.0000e+00 - val_loss: 23.3144\n",
            "Epoch 57/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 1.0000 - loss: 0.0427 - val_accuracy: 0.0000e+00 - val_loss: 23.4636\n",
            "Epoch 58/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0363 - val_accuracy: 0.0000e+00 - val_loss: 23.6341\n",
            "Epoch 59/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0365 - val_accuracy: 0.0000e+00 - val_loss: 23.7837\n",
            "Epoch 60/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 1.0000 - loss: 0.0345 - val_accuracy: 0.0000e+00 - val_loss: 23.9250\n",
            "Epoch 61/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 1.0000 - loss: 0.0335 - val_accuracy: 0.0000e+00 - val_loss: 24.0799\n",
            "Epoch 62/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0295 - val_accuracy: 0.0000e+00 - val_loss: 24.2216\n",
            "Epoch 63/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0296 - val_accuracy: 0.0000e+00 - val_loss: 24.3668\n",
            "Epoch 64/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0286 - val_accuracy: 0.0000e+00 - val_loss: 24.5006\n",
            "Epoch 65/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 0.0000e+00 - val_loss: 24.6199\n",
            "Epoch 66/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0256 - val_accuracy: 0.0000e+00 - val_loss: 24.7498\n",
            "Epoch 67/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0238 - val_accuracy: 0.0000e+00 - val_loss: 24.8806\n",
            "Epoch 68/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0205 - val_accuracy: 0.0000e+00 - val_loss: 24.9989\n",
            "Epoch 69/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0226 - val_accuracy: 0.0000e+00 - val_loss: 25.0791\n",
            "Epoch 70/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0223 - val_accuracy: 0.0000e+00 - val_loss: 25.1579\n",
            "Epoch 71/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0202 - val_accuracy: 0.0000e+00 - val_loss: 25.2632\n",
            "Epoch 72/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.0000e+00 - val_loss: 25.4255\n",
            "Epoch 73/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0184 - val_accuracy: 0.0000e+00 - val_loss: 25.5954\n",
            "Epoch 74/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.0000e+00 - val_loss: 25.7221\n",
            "Epoch 75/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 0.0000e+00 - val_loss: 25.8177\n",
            "Epoch 76/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 1.0000 - loss: 0.0159 - val_accuracy: 0.0000e+00 - val_loss: 25.8913\n",
            "Epoch 77/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.0000e+00 - val_loss: 25.9582\n",
            "Epoch 78/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0128 - val_accuracy: 0.0000e+00 - val_loss: 26.0142\n",
            "Epoch 79/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0135 - val_accuracy: 0.0000e+00 - val_loss: 26.0898\n",
            "Epoch 80/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.0000e+00 - val_loss: 26.1767\n",
            "Epoch 81/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0122 - val_accuracy: 0.0000e+00 - val_loss: 26.2683\n",
            "Epoch 82/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0114 - val_accuracy: 0.0000e+00 - val_loss: 26.3539\n",
            "Epoch 83/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0117 - val_accuracy: 0.0000e+00 - val_loss: 26.4440\n",
            "Epoch 84/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.0000e+00 - val_loss: 26.5229\n",
            "Epoch 85/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0116 - val_accuracy: 0.0000e+00 - val_loss: 26.5900\n",
            "Epoch 86/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 1.0000 - loss: 0.0109 - val_accuracy: 0.0000e+00 - val_loss: 26.6665\n",
            "Epoch 87/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.0000e+00 - val_loss: 26.7422\n",
            "Epoch 88/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0098 - val_accuracy: 0.0000e+00 - val_loss: 26.8189\n",
            "Epoch 89/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0095 - val_accuracy: 0.0000e+00 - val_loss: 26.9057\n",
            "Epoch 90/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.0000e+00 - val_loss: 26.9672\n",
            "Epoch 91/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.0000e+00 - val_loss: 27.0191\n",
            "Epoch 92/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0091 - val_accuracy: 0.0000e+00 - val_loss: 27.0891\n",
            "Epoch 93/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0083 - val_accuracy: 0.0000e+00 - val_loss: 27.1452\n",
            "Epoch 94/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0080 - val_accuracy: 0.0000e+00 - val_loss: 27.2021\n",
            "Epoch 95/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.0000e+00 - val_loss: 27.2560\n",
            "Epoch 96/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 1.0000 - loss: 0.0081 - val_accuracy: 0.0000e+00 - val_loss: 27.3171\n",
            "Epoch 97/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0076 - val_accuracy: 0.0000e+00 - val_loss: 27.3828\n",
            "Epoch 98/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 1.0000 - loss: 0.0077 - val_accuracy: 0.0000e+00 - val_loss: 27.4517\n",
            "Epoch 99/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0068 - val_accuracy: 0.0000e+00 - val_loss: 27.5318\n",
            "Epoch 100/100\n",
            "\u001b[1m5/5\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 1.0000 - loss: 0.0066 - val_accuracy: 0.0000e+00 - val_loss: 27.6333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " d. Output"
      ],
      "metadata": {
        "id": "mxks655_MdoX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_words=[index_to_word[index] for index in contexts[0]]\n",
        "\n",
        "input_data=np.expand_dims(contexts[0],axis=0)\n",
        "print(input_data)\n",
        "\n",
        "pred=model.predict(input_data)\n",
        "predicted_index=np.argmax(pred[0])\n",
        "\n",
        "print(\"Context words:\", test_words)\n",
        "print(\"Predicted terget word : \",index_to_word[predicted_index])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5diZRPqgIl4p",
        "outputId": "996a73ad-c7b2-4fb2-c662-930cb5bd764b"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 6  7 27 28]]\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n",
            "Context words: ['deep', 'learning', 'a', 'subset']\n",
            "Predicted terget word :  is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u6cPY8HTNP5O"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}